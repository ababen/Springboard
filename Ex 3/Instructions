Data Wrangling Exercise 3: Human Activity Recognition (Optional)
Note: This data wrangling project is known to be a bit challenging, hence we've marked it as optional. However, we recommend you at least try it out when you're more comfortable with R later in the curriculum, since it's a good example of a messy, real-world data set that you'd encounter in a data science job.
The goal of this project is to get you some practice in processing real world datasets using the tools and techniques you learned above. Using your Capstone dataset here will get you one step closer to the finish line. If for some reason (e.g. the chosen dataset is already tidy) your Capstone dataset is unsuitable, you can use the Samsung Galaxy S Smartphone dataset, available via UCI. A full description of that data is available here and also in the README file included with the data.

We give submission guidelines below assuming the UCI smartphone data set. This data set is organized in a way that makes it hard to use at first. You will need to use several data transformation techniques to put it into a usable, tidy state. Here's a great post in the workshop community which gives several handy tips on how to approach this. Discuss with your mentor if needed!
You should create one R script called run_analysis.R that does the following.
Merges the training and the test sets to create one data set.
Extracts columns containing mean and standard deviation for each measurement (Hint: Since some feature/column names are repeated, you may need to use the make.names() function in R)
Creates variables called ActivityLabel and ActivityName that label all observations with the corresponding activity labels and names respectively
From the data set in step 3, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

Description of Data: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
Helpful post: https://plus.google.com/u/0/106703650981676573830/posts/V1WBssUzz5z

Submit: 
The tidy data set as described above
A link to a Github repository with your script for performing the analysis, and 
A code book that describes the variables, the data, and any transformations or work that you performed to clean up the data called CodeBook.md. You should also include a README.md in the repo with your scripts. This repo explains how all of the scripts work and how they are connected. 